# -*- coding: utf-8 -*-
"""KSE525_termproject_Hyewon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cdCn-57QUVa0N5HxicTKyZt9RaSF3NgH
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Read data files
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')
train_df.head()

# Check data shape
train_df.shape, test_df.shape

# Divide to numerical and categorical features
num_feats = train_df.dtypes[train_df.dtypes != 'object'].index
print("Number of numerical features: ", len(num_feats))
cat_feats = train_df.dtypes[train_df.dtypes == 'object'].index
print("Number of categorical features: ", len(cat_feats))

print("Numerical features: ", train_df[num_feats].columns)
print("Categorical features: ", train_df[cat_feats].columns)

# Detect outliers and remove them
def detect_outliers(df, n, features):
    outlier_indices = []
    for col in features:
        Q1 = np.percentile(df[col], 25)
        Q3 = np.percentile(df[col], 75)
        IQR = Q3 - Q1
        outlier_range = 1.5 * IQR
        outlier_list_col = df[(df[col] < Q1 - outlier_range) | (df[col] > Q3 + outlier_range)].index
        outlier_indices.extend(outlier_list_col)
    outlier_indices = Counter(outlier_indices)
    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)
    return multiple_outliers

outliers_to_drop = detect_outliers(train_df, 2, train_df[num_feats].columns.drop('SalePrice'))
train_df.loc[outliers_to_drop]
train_df = train_df.drop(outliers_to_drop, axis=0).reset_index(drop=True)
train_df.shape

#Visualize correlations among numerical features
corr_data = train_df[num_feats]
colormap = plt.cm.PuBu
sns.set(font_scale = 1.0)
f, ax = plt.subplots(figsize = (14, 12))
plt.title('Correlation of numerical features with SalePrice', y=1, size=18)
sns.heatmap(corr_data.corr(), square=True, linewidths=0.1, cmap=colormap,linecolor='white', vmax=0.8)

k = 11
cols = corr_data.corr().nlargest(k, 'SalePrice')['SalePrice'].index
print(cols)
cm = np.corrcoef(train_df[cols].values.T)
f, ax = plt.subplots(figsize = (12, 10))
sns.heatmap(cm, vmax=0.8, linewidths=0.1, square=True, annot=True, cmap=colormap, linecolor="white", 
            xticklabels=cols.values, annot_kws={'size':14}, yticklabels=cols.values)

# Categorical features
for cat in list(cat_feats):
    print(train_df[cat].value_counts())
    print('-'*50)

cat_feats_list = list(cat_feats)
n_rows = 15
n_cols = 3

f, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*4, n_rows*3))
for r in range(0, n_rows):
    for c in range(0, n_cols):
        i = r*n_cols + c
        if i < len(cat_feats_list):
            sns.boxplot(x=cat_feats_list[i], y=train_df['SalePrice'], data=train_df, ax=axs[r][c])

plt.tight_layout()
plt.show()

num_strong_corr = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF']
num_weak_corr = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',
                 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 
                 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'WoodDeckSF', 'OpenPorchSF', 
                 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']
cat_strong_corr = ['MSZoning', 'Neighborhood', 'MasVnrType', 'ExterQual', 'BsmtQual', 'CentralAir', 'Electrical', 'KitchenQual', 'SaleType']
cat_weak_corr = ['Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 
                 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterCond', 'Foundation', 
                 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'Functional', 'FireplaceQu', 
                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleCondition']

f, ax = plt.subplots(1, 1, figsize=(10, 6))
g = sns.distplot(train_df['SalePrice'], color='b', label='Skewness: {:2f}'.format(train_df['SalePrice'].skew()), ax=ax)
g = g.legend(loc = 'best')
print("Skewness: %f" % train_df['SalePrice'].skew())
print("Kurtosis: %f" % train_df['SalePrice'].kurt())

train_df['SalePrice_log'] = train_df['SalePrice'].map(lambda i: np.log(i) if i>0 else 0)

f, ax = plt.subplots(1, 1, figsize=(10, 6))
g = sns.distplot(train_df['SalePrice_log'], color='b', label='Skewness: {:2f}'.format(train_df['SalePrice_log'].skew()), ax=ax)
g = g.legend(loc = 'best')
print("Skewness: %f" % train_df['SalePrice_log'].skew())
print("Kurtosis: %f" % train_df['SalePrice_log'].kurt())
train_df.drop('SalePrice', axis=1, inplace=True)

print("Train----------------------")
for col in train_df.columns:
    missingperc = 'column: {}\t Nan value: {:.2f}%'.format(col, 100*(train_df[col].isnull().sum() / train_df[col].shape[0]))
    print(missingperc)
print("Test----------------------")
for col in test_df.columns:
    missingperc = 'column: {}\t Nan value: {:.2f}%'.format(col, 100*(test_df[col].isnull().sum() / test_df[col].shape[0]))
    print(missingperc)

missing = train_df.isnull().sum()
missing = missing[missing > 0]
missing.sort_values(inplace=True)
missing.plot.bar(figsize = (12, 6))

cat_missing = []
for col in cat_feats:
    if train_df[col].isnull().sum() > 0:
        cat_missing.append(col)

for col in cat_missing:
    train_df[col].fillna('None', inplace=True)
    test_df[col].fillna('None', inplace=True)
    
total = train_df.isnull().sum().sort_values(ascending=False)
percent = (train_df.isnull().sum() / train_df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(5)

train_df.fillna(train_df.mean(), inplace=True)
test_df.fillna(test_df.mean(), inplace=True)
total = train_df.isnull().sum().sort_values(ascending=False)
percent = (train_df.isnull().sum() / train_df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(5)

id_test = test_df['Id']
num_feats_drop = num_weak_corr
cat_feats_drop = cat_weak_corr

cols_drop = ['Id'] + num_feats_drop + cat_feats_drop
for df in [train_df, test_df]:
    df.drop(cols_drop, axis=1, inplace=True)
train_df.head()

train_df.shape, test_df.shape

cat_feats_list = cat_strong_corr.copy()
cat_feats_list.remove('Neighborhood')

for cat in cat_feats_list:
    sns.violinplot(x=cat, y=train_df['SalePrice_log'], data=train_df)
    plt.show()

f, ax = plt.subplots()
f.set_size_inches(16, 5)
sns.violinplot(x='Neighborhood', y=train_df['SalePrice_log'], data=train_df, ax=ax)
plt.xticks(rotation=45)
plt.show()

for cat in cat_feats_list:
    g = train_df.groupby(cat)['SalePrice_log'].mean()
    print(g)

msz_cat2 = ['RM', 'RH']
msz_cat3 = ['RL', 'FV']

mas_cat2 = ['Stone', 'BrkFace']

nbhd_cat2 = ['Blmngtn', 'ClearCr', 'CollgCr', 'Crawfor', 'Gilbert', 'NWAmes', 'Somerst', 'Timber', 'Veenker']
nbhd_cat3 = ['NoRidge', 'NridgHt', 'StoneBr']

st_cat1 = ['Oth']
st_cat3 = ['CWD']
st_cat4 = ['New', 'Con']

for df in [train_df, test_df]:
    df['MSZ_num'] = 1
    df.loc[(df['MSZoning'].isin(msz_cat2)), 'MSZ_num'] = 2
    df.loc[(df['MSZoning'].isin(msz_cat3)), 'MSZ_num'] = 3
    
    df['Mas_num'] = 1
    df.loc[(df['MasVnrType'].isin(mas_cat2)), 'Mas_num'] = 2
    
    df['ExtQ_num'] = 1
    df.loc[(df['ExterQual'] == 'TA'), 'ExtQ_num'] = 2
    df.loc[(df['ExterQual'] == 'Gd'), 'ExtQ_num'] = 3
    df.loc[(df['ExterQual'] == 'Ex'), 'ExtQ_num'] = 4
    
    df['BsQ_num'] = 1 
    df.loc[(df['BsmtQual'] == 'Gd'), 'BsQ_num'] = 2 
    df.loc[(df['BsmtQual'] == 'Ex'), 'BsQ_num'] = 3
    
    df['CA_num'] = 0 
    df.loc[(df['CentralAir'] == 'Y'), 'CA_num'] = 1
    
    df['Elc_num'] = 1 
    df.loc[(df['Electrical'] == 'SBrkr'), 'Elc_num'] = 2 
    
    df['KiQ_num'] = 1 
    df.loc[(df['KitchenQual'] == 'TA'), 'KiQ_num'] = 2 
    df.loc[(df['KitchenQual'] == 'Gd'), 'KiQ_num'] = 3 
    df.loc[(df['KitchenQual'] == 'Ex'), 'KiQ_num'] = 4
    
    df['SlTy_num'] = 2 
    df.loc[(df['SaleType'].isin(st_cat1)), 'SlTy_num'] = 1 
    df.loc[(df['SaleType'].isin(st_cat3)), 'SlTy_num'] = 3 
    df.loc[(df['SaleType'].isin(st_cat4)), 'SlTy_num'] = 4
    
    df['NbHd_num'] = 1 
    df.loc[(df['Neighborhood'].isin(nbhd_cat2)), 'NbHd_num'] = 2 
    df.loc[(df['Neighborhood'].isin(nbhd_cat3)), 'NbHd_num'] = 3

new_col_HM = train_df[['SalePrice_log', 'MSZ_num', 'Mas_num', 'ExtQ_num', 'BsQ_num', 'CA_num', 'Elc_num', 'KiQ_num', 'SlTy_num', 'NbHd_num']]
colormap = plt.cm.PuBu
plt.figure(figsize=(10, 8))
plt.title('Correlation of New Features', y=1, size=15)
sns.heatmap(new_col_HM.corr(), linewidths=0.1, vmax=1.0, square=True, annot=True, cmap=colormap, linecolor="white", annot_kws={'size':14})

train_df.drop(['MSZoning', 'Neighborhood', 'MasVnrType', 'ExterQual', 'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType', 'MSZ_num', 'Mas_num', 'CA_num', 'Elc_num', 'SlTy_num'], axis = 1, inplace = True)
test_df.drop(['MSZoning', 'Neighborhood', 'MasVnrType', 'ExterQual', 'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType', 'MSZ_num', 'Mas_num', 'CA_num', 'Elc_num', 'SlTy_num'], axis = 1, inplace = True)

train_df.head()

test_df.head()

from sklearn.model_selection import train_test_split
from sklearn import metrics

X_train = train_df.drop('SalePrice_log', axis=1).values
target_label = train_df['SalePrice_log'].values
X_test = test_df.values
X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.2, random_state=2000)

import xgboost
regressor = xgboost.XGBRegressor(colsample_bytree = 0.5, learning_rate = 0.005, min_child_weight = 1, max_depth = 3, 
                                 subsample = 0.5, n_estimators = 2000, random_state = 7)
regressor.fit(X_tr, y_tr)

y_hat = regressor.predict(X_tr)
plt.scatter(y_tr, y_hat, alpha=0.2)
plt.xlabel('Targets (y_tr)', size=18)
plt.ylabel('Predictions (y_hat)', size=18)
plt.show()
regressor.score(X_tr, y_tr)

y_hat_test = regressor.predict(X_vld)
plt.scatter(y_vld, y_hat_test, alpha=0.2)
plt.xlabel('Targets (y_vld)', size=18)
plt.ylabel('Predictions (y_hat_test)', size=18)
plt.show()
regressor.score(X_vld, y_vld)

from sklearn.model_selection import cross_val_score
accuracy = cross_val_score(estimator=regressor, X=X_tr, y=y_tr, cv=10)
print(accuracy.mean(), accuracy.std())

use_logvals = 1

pred_xgb = regressor.predict(X_test)
sub_xgb = pd.DataFrame()
sub_xgb['Id'] = id_test
sub_xgb['SalePrice'] = pred_xgb

if use_logvals == 1:
    sub_xgb['SalePrice'] = np.exp(sub_xgb['SalePrice'])
    
sub_xgb.to_csv('xgb_2.csv', index=False)