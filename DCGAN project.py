# -*- coding: utf-8 -*-
"""ai project_DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YGVNSfCxqX7mST4HtRLxDr8_OAxkA0ZK
"""

import os
import random

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import imageio
from IPython.display import HTML

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torchvision.utils import make_grid
from tqdm import tqdm

def vis_image(image):
    plt.imshow(image[0].detach().cpu().numpy(),cmap='gray')
    plt.show()

def save_gif(training_progress_images, images):
    img_grid = make_grid(images.data)
    img_grid = np.transpose(img_grid.detach().cpu().numpy(), (1, 2, 0))
    img_grid = 255. * img_grid 
    img_grid = img_grid.astype(np.uint8)
    training_progress_images.append(img_grid)
    imageio.mimsave('/gdrive/My Drive/img_align_celeba/img/training_progress.gif', training_progress_images)
    return training_progress_images

# visualize gif file
def vis_gif(training_progress_images):
    fig = plt.figure()
    
    ims = []
    for i in range(len(training_progress_images)):
        im = plt.imshow(training_progress_images[i], animated=True)
        ims.append([im])

    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)
    
    html = ani.to_html5_video()
    HTML(html)

# visualize gif file
def plot_gif(training_progress_images, plot_length=10):
    plt.close()
    fig = plt.figure()
    
    total_len = len(training_progress_images)
    for i in range(plot_length):
        im = plt.imshow(training_progress_images[int(total_len/plot_length)*i])
        plt.show()

def save_image_list(dataset, real):
    if real:
        base_path = '/gdrive/My Drive/img_align_celeba/img/real'
    else:
        base_path = '/gdrive/My Drive/img_align_celeba/img/fake'
    
    dataset_path = []
    
    for i in range(len(dataset)):
        save_path =  f'{base_path}/image_{i}.png'
        dataset_path.append(save_path)
        vutils.save_image(dataset[i], save_path)
    
    return base_path

from google.colab import drive
drive.mount('/gdrive', force_remount=True)

!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip

import zipfile

with zipfile.ZipFile("celeba.zip","r") as zip_ref:
  zip_ref.extractall("data_faces/")

root = 'data_faces/img_align_celeba'
img_list = os.listdir(root)
print(len(img_list))

dataroot = './data_faces'
ngpu = 1
dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                                   transforms.Resize(64),
                                   transforms.CenterCrop(64),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                ]))

dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, drop_last=True)

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(), (1,2,0)))

nc = 3 # number of channels, RGB
nz = 100 # input noise dimension
ngf = 64 # number of generator filters
ndf = 64 #number of discriminator filters

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        output = self.main(input)
        return output

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        output = self.main(input)
        return output.view(-1, 1).squeeze(1)

if not os.path.exists('/gdrive/My Drive/img_align_celeba/checkpoint'):
    os.mkdir('/gdrive/My Drive/img_align_celeba/checkpoint')
    
if not os.path.exists('/gdrive/My Drive/img_align_celeba/dataset'):
    os.mkdir('/gdrive/My Drive/img_align_celeba/dataset')
    
if not os.path.exists('/gdrive/My Drive/img_align_celeba/img'):
    os.mkdir('/gdrive/My Drive/img_align_celeba/img')
    
if not os.path.exists('/gdrive/My Drive/img_align_celeba/img/real'):
    os.mkdir('/gdrive/My Drive/img_align_celeba/img/real')

if not os.path.exists('/gdrive/My Drive/img_align_celeba/img/fake'):
    os.mkdir('/gdrive/My Drive/img_align_celeba/img/fake')

netG = Generator().cuda()
netG.load_state_dict(torch.load('/gdrive/My Drive/img_align_celeba/checkpoint/netG_epoch_9.pth'))
netD = Discriminator().cuda()
netD.load_state_dict(torch.load('/gdrive/My Drive/img_align_celeba/checkpoint/netD_epoch_9.pth'))

optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))

noise = torch.randn(128, 100).cuda()

# Commented out IPython magic to ensure Python compatibility.
fixed_noise = torch.randn(128, nz, 1, 1).cuda()

criterion = nn.BCELoss()

n_epoch = 20
training_progress_images_list = []
for epoch in tqdm(range(n_epoch)):
    for i, (data, _) in enumerate(dataloader):
        # Update D network
        # train with real
        netD.zero_grad()
        data = data.cuda()
        batch_size = data.size(0)
        label = torch.ones((batch_size,)).cuda() # real label = 1
        output = netD(data)
        errD_real = criterion(output, label) 
        D_x = output.mean().item()

        # train with fake
        noise = torch.randn(128, nz, 1, 1).cuda()
        fake = netG(noise)
        label = torch.zeros((batch_size,)).cuda() # fake label = 0
        output = netD(fake.detach()) #unless use detach, gradient flows to generator but we only want to update discriminator here. So we have to detach fake image from computation of gradient.
        errD_fake = criterion(output, label)
        D_G_z1 = output.mean().item()
        
        # Loss backward
        errD = errD_real + errD_fake
        errD.backward()
        optimizerD.step()

        # Update G network
        netG.zero_grad()
        label = torch.ones((batch_size,)).cuda()  # here we make label as 1 to fool D!
        output = netD(fake)
        errG = criterion(output, label)
        D_G_z2 = output.mean().item()

        errG.backward()
        optimizerG.step()
        
    print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' 
#               % (epoch, n_epoch, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
    
    #save the output
    fake = netG(fixed_noise)
    training_progress_images_list = save_gif(training_progress_images_list, fake)  # Save fake image while training!
    
    # Check pointing for every epoch
    torch.save(netG.state_dict(), '/gdrive/My Drive/img_align_celeba/checkpoint/netG_epoch_%d.pth' % (9+epoch))
    torch.save(netD.state_dict(), '/gdrive/My Drive/img_align_celeba/checkpoint/netD_epoch_%d.pth' % (9+epoch))

plot_gif(training_progress_images_list)

!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1InzR1qylS3Air4IvpS9CoamqJ0r9bqQg' -O inception.py

!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1AtTxnuasIaSTTmI9MI7k8ugY8KJ1cw3Y' -O fid_score.py

from fid_score import calculate_fid_given_paths  # The code is downloaded from github

test_dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                                   transforms.Resize(64),
                                   transforms.CenterCrop(64),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                ]))

dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True, num_workers=2)

for i, (data, _) in enumerate(dataloader):
    real_dataset = data
    break
    
noise = torch.randn(1000, 100, 1, 1).cuda()
fake_dataset = netG(noise)

real_image_path_list = save_image_list(real_dataset, True)
fake_image_path_list = save_image_list(fake_dataset, False)

fid_value = calculate_fid_given_paths([real_image_path_list, fake_image_path_list],
                                                          100, 
                                                          True,
                                                          2048)

print (f'FID score: {fid_value}')