{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marketing channel classification model\n",
    "마케팅 채널 A와 B를 구분할 수 있는 **채널 분류 모델**  \n",
    "\n",
    "타겟변수가 marketing_channel로 categorical variable이고, A와 B 두 가지로 분류되는 **binary classification** 문제이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import missingno as msno\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv('user_info.csv')\n",
    "user_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 처리를 하기 위해 우선 결측치의 패턴을 확인해야 한다.  \n",
    "결측치는 세 개의 변수에 집중되어 있고, age_group의 약 2%, visits와 revenue의 9%를 차지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = user_info.drop(['user_uuid'], axis=1) #unnecessary column\n",
    "user_info.isnull().sum()\n",
    "user_info.isnull().sum() / len(user_info) #explore missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치를 시각화해보면 age_group의 결측치는 완전 무작위 결측으로 보이고, visits와 revenue의 결측치는 서로 연관되어 있지만 비관측된 다른 변수들과는 무관한 무작위 결측으로 판단된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(user_info, figsize=(10, 5))\n",
    "msno.heatmap(user_info, figsize=(10, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age_group의 결측치는 완전 무작위 결측이며 2%로 매우 적으므로 제거한다.  \n",
    "visits와 revenue의 결측치는 의미상으로 '회원가입 후 한번도 방문하지 않고 매출이 발생하지 않은 사용자'를 뜻하므로, 0으로 대체하는 것이 합리적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.dropna(subset=['age_group'], axis=0, inplace=True)\n",
    "user_info.fillna({'visits':0, 'revenue':0}, inplace=True)\n",
    "user_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 이상치를 판단하는데 가입기간을 고려하기 위해 새로운 column을 만들었다.  \n",
    "period column은 date_joined를 기준으로 데이터 추출 시점까지의 기간(일)으로 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extraction_date = datetime.datetime(2030, 12, 31)\n",
    "user_info['period'] = user_info['date_joined'].apply(lambda x: (data_extraction_date - pd.to_datetime(x)).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical features 중에 이상치를 제거하기 위해 IQR rule을 사용하였다.  \n",
    "단순히 IQR rule을 사용해서 이상치로 분류되는 데이터를 모두 제거하기보다, 해당 feature의 대표 통계량과 boxplot을 종합적으로 판단하여 이상치를 처리하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier(df, n, features):\n",
    "  outlier_indices = []\n",
    "  for col in features:\n",
    "    Q1 = np.percentile(df[col], 25)\n",
    "    Q3 = np.percentile(df[col], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_range = 1.5 * IQR\n",
    "    outlier_col = df[(df[col] < Q1 - outlier_range) | (df[col] > Q3 + outlier_range)].index\n",
    "    outlier_indices.extend(outlier_col)\n",
    "  outlier_indices = Counter(outlier_indices)\n",
    "  outliers = list(k for k, v in outlier_indices.items() if v >= n)\n",
    "  return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 visits의 경우는 평균이 9.2이고 표준편차가 9.6이므로 대략 0 ~ 19 사이에 68%의 데이터가 존재한다.  \n",
    "가입한 사용자 중 앱을 한번도 방문하지 않은 경우는 충분히 존재할 수 있으므로, 방문 수가 극단적으로 많은 경우만 이상치로 간주하는 것이 합리적이다.  \n",
    "계산된 이상치의 수는 19,170개인데, 이들 중 일부를 살펴보았을 때 정상적인 값으로 판단되는 데이터가 다수 존재한다.  \n",
    "예를 들어, period가 200일 이상으로 충분히 긴 경우라면 30회 이상의 방문 수가 발생할 가능성이 있으므로 이상치로 보기 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_info['visits'].describe())\n",
    "plt.boxplot(user_info['visits'])\n",
    "plt.show()\n",
    "\n",
    "outlier_visits_calc = detect_outlier(user_info, 1, ['visits'])\n",
    "print('num. of outliers in visits: ', len(outlier_visits_calc))\n",
    "print(user_info.loc[outlier_visits_calc].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 계산된 이상치들 중 초반 데이터(visits이 30 ~ 40 이고 period가 220 ~ 240)들은 period-visits scatter plot에서는 전혀 이상치로 보이지 않는다.   \n",
    "scatter plot에서 period와 관계없이 visits이 0인 경우는 충분히 발생할 수 있으므로 이상치로 처리하지 않는다.  \n",
    "그러나 period가 짧은데 visits이 극단적으로 많이 나온 경우는 이상치로 볼 수 있으므로, 해당 데이터는 제거해준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='period', y='visits', data=user_info)\n",
    "outlier_visits_drop = user_info[(user_info['period'] < 300) & (user_info['visits'] > 170)].index\n",
    "user_info = user_info.drop(outlier_visits_drop, axis=0)\n",
    "user_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revenue의 경우는 평균이 170.7이고 표준편차가 167.6이므로 대략 3 ~ 340 사이에 68%의 데이터가 존재한다.  \n",
    "마찬가지로 앱을 한번도 방문하지 않은 사용자는 revenue도 0일 것이므로, revenue가 극단적으로 큰 경우만 이상치로 고려하였다.  \n",
    "계산된 이상치의 수는 23,939개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_info['revenue'].describe())\n",
    "plt.boxplot(user_info['revenue'])\n",
    "plt.show()\n",
    "\n",
    "outlier_revenue_calc = detect_outlier(user_info, 1, ['revenue'])\n",
    "print('num. of outliers in revenue: ', len(outlier_revenue_calc))\n",
    "print(user_info.loc[outlier_revenue_calc].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='period', y='revenue', data=user_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대신 basket size를 구하여 visits 대비 revenue가 극단적으로 큰 데이터를 이상치로 판단하였다.  \n",
    "user_info에 basket_size column을 추가하여 boxplot을 그려 2000 이상인 이상치를 제거하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_per_vis(x):\n",
    "  return x['revenue']/(x['visits'] + 0.000001)\n",
    "\n",
    "user_info['basket_size'] = user_info.apply(rev_per_vis, axis=1)\n",
    "print(user_info['basket_size'].describe())\n",
    "plt.boxplot(user_info['basket_size'])\n",
    "plt.show()\n",
    "\n",
    "outlier_basket_size_calc = detect_outlier(user_info, 1, ['basket_size'])\n",
    "print('num. of outliers in basket_size: ', len(outlier_basket_size_calc))\n",
    "print(user_info.loc[outlier_basket_size_calc].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_basket_size_drop = user_info[(user_info['basket_size'] > 2000)].index\n",
    "user_info = user_info.drop(outlier_basket_size_drop, axis=0)\n",
    "print(user_info.shape)\n",
    "plt.boxplot(user_info['basket_size'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.to_csv('user_info_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv('user_info_preprocessed.csv')\n",
    "user_info = user_info.drop(['date_joined'], axis=1) #used as period\n",
    "user_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명변수별 타겟변수와의 관계를 시각화해보면, 타겟변수를 두 그룹으로 분류할 가능성이 높은 설명변수가 두드러지게 나타나지 않는다.  \n",
    "즉, 모든 변수들에 대해 Channel A와 B라는 라벨이 고르게 분포한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = user_info[user_info.columns.difference(['marketing_channel'])]\n",
    "feature_name = x.columns\n",
    "y = user_info['marketing_channel']\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "for col_idx in range(len(feature_name)):\n",
    "    plt.subplot(4, 2, col_idx + 1)\n",
    "    plt.hist(user_info[user_info['marketing_channel'] == 'channel_A'][feature_name[col_idx]], label='Channel A', alpha=0.5)\n",
    "    plt.hist(user_info[user_info['marketing_channel'] == 'channel_B'][feature_name[col_idx]], label='Channel B', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.title(\"Feature: \" + feature_name[col_idx], fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = x.dtypes[x.dtypes != 'object'].index\n",
    "cat_feats = x.dtypes[x.dtypes == 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x[num_feats]) #data scaling numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in list(cat_feats):\n",
    "    print(x[cat].value_counts())\n",
    "    print('-'*50)\n",
    "x_dummy = pd.get_dummies(x, columns=cat_feats) #convert categorical features into dummy variables\n",
    "x_rev = np.concatenate((x_scaled, x_dummy), axis=1) #merge with scaled numerical features\n",
    "print(x_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_a = (y == 'channel_A')\n",
    "y_a.value_counts(normalize=True) #convert target as boolean (channel_A == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel A와 B가 비대칭하게 분포하는 데이터셋이므로, 타겟값의 분포가 training set과 test set에 비슷한 비율로 추출되었는지 확인해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_rev, y_a, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 분류 모델의 성능을 비교하여 적절한 모델을 선택한다.  \n",
    "이 과정에서 cross validation을 사용하는데, 클래스가 비대칭한 데이터셋이므로 층화추출(stratified)을 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3, shuffle = True, random_state=42) \n",
    "\n",
    "def display_scores(model_name, score):\n",
    "    print('Model: ', model_name)\n",
    "    print('Scores: ', score)\n",
    "    print('Mean score: ', score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=1)\n",
    "sgd.fit(x_train, y_train)\n",
    "score_sgd = cross_val_score(sgd, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('SGD classifier', score_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "tree = DTC(criterion='entropy')\n",
    "tree.fit(x_train, y_train)\n",
    "score_tree = cross_val_score(tree, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('Decision tree', score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "forest = RFC(criterion='gini', n_estimators=350, n_jobs=4)\n",
    "forest.fit(x_train, y_train)\n",
    "score_forest = cross_val_score(forest, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('Random forest', score_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "score_knn = cross_val_score(knn, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('KNN', score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimators=500, random_state=1)\n",
    "xgb.fit(x_train, y_train)\n",
    "score_xgb = cross_val_score(xgb, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('XGBoost', score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(n_estimators=500, random_state=1)\n",
    "lgbm.fit(x_train, y_train)\n",
    "score_lgbm = cross_val_score(lgbm, x_train, y_train, cv=skfold, scoring='accuracy')\n",
    "display_scores('LightGBM', score_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 모델들 중에 정확도가 가장 높은 LightGBM 모델을 선택하여, hyperparameter tuning을 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류모델이므로 성능 지표로 confusion matrix의 accuracy, precision, recall, f1, roc-auc 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before tuning\n",
    "tic = time.time()\n",
    "\n",
    "lgbm_before = LGBMClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                             objective= 'binary', seed=27)\n",
    "lgbm_before.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = lgbm_before.predict(x_val)\n",
    "y_pred_proba = lgbm_before.predict_proba(x_val)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "lgbm_roc_score = roc_auc_score(y_val, y_pred_proba, average='macro')\n",
    "toc = time.time()\n",
    "\n",
    "print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))\n",
    "print('time elapsed:', toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8196, Precision: 0.8266, Recall: 0.9863, F1: 0.8994  \n",
    "ROC AUC: 0.7663  \n",
    "time elapsed: 1.1253783702850342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth, num_leaves, min_child_samples 순으로 hyperparameter tuning을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "lgbm = LGBMClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                     objective= 'binary', seed=27)\n",
    "param_1 = {'max_depth':range(10,31)}\n",
    "gridcv = GridSearchCV(lgbm, param_grid=param_1, cv=3)\n",
    "gridcv.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = gridcv.predict(x_val)\n",
    "y_pred_proba = gridcv.predict_proba(x_val)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "lgbm_roc_score = roc_auc_score(y_val, y_pred_proba, average='macro')\n",
    "toc = time.time()\n",
    "\n",
    "print(gridcv.best_params_)\n",
    "print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))\n",
    "print('time elapsed:', toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'max_depth': 12}  \n",
    "Accuracy: 0.8197, Precision: 0.8268, Recall: 0.9860, F1: 0.8994  \n",
    "ROC AUC: 0.7664  \n",
    "time elapsed: 72.57131934165955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "lgbm = LGBMClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                      max_depth=12,\n",
    "                      objective= 'binary', seed=27)\n",
    "param_2 = {'num_leaves':range(10,31)}\n",
    "gridcv = GridSearchCV(lgbm, param_grid=param_2, cv=3)\n",
    "gridcv.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = gridcv.predict(x_val)\n",
    "y_pred_proba = gridcv.predict_proba(x_val)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "lgbm_roc_score = roc_auc_score(y_val, y_pred_proba, average='macro')\n",
    "toc = time.time()\n",
    "\n",
    "print(gridcv.best_params_)\n",
    "print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))\n",
    "print('time elapsed:', toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'num_leaves': 11}  \n",
    "Accuracy: 0.8194, Precision: 0.8283, Recall: 0.9829, F1: 0.8990  \n",
    "ROC AUC: 0.7665  \n",
    "time elapsed: 79.52990674972534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "lgbm = LGBMClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                      max_depth=12, num_leaves=11,\n",
    "                      objective= 'binary', seed=27)\n",
    "param_3 = {'min_child_samples':range(10,110,10)}\n",
    "gridcv = GridSearchCV(lgbm, param_grid=param_3, cv=3)\n",
    "gridcv.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = gridcv.predict(x_val)\n",
    "y_pred_proba = gridcv.predict_proba(x_val)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "lgbm_roc_score = roc_auc_score(y_val, y_pred_proba, average='macro')\n",
    "toc = time.time()\n",
    "\n",
    "print(gridcv.best_params_)\n",
    "print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))\n",
    "print('time elapsed:', toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'min_child_samples': 30}  \n",
    "Accuracy: 0.8195, Precision: 0.8283, Recall: 0.9830, F1: 0.8991  \n",
    "ROC AUC: 0.7665  \n",
    "time elapsed: 42.54118061065674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 hyperparameter로 설정한 모델을 학습시켜 test set에 대해 최종 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after tuning \n",
    "lgbm_after = LGBMClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                            max_depth=12, num_leaves=11,\n",
    "                            min_child_samples=30,\n",
    "                            objective= 'binary', seed=27)\n",
    "lgbm_after.fit(x_train, y_train)\n",
    "\n",
    "#final test\n",
    "y_pred = lgbm_after.predict(x_test)\n",
    "y_pred_proba = lgbm_after.predict_proba(x_test)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "lgbm_roc_score = roc_auc_score(y_test, y_pred_proba, average='macro')\n",
    "\n",
    "print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
